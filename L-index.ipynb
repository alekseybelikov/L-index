{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scholarly\n",
    "import datetime\n",
    "import math\n",
    "import logging\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "from difflib import SequenceMatcher\n",
    "from fpdf import FPDF\n",
    "from fpdf.enums import XPos, YPos, Align\n",
    "\n",
    "try:\n",
    "    from scholarly._navigator import MaxTriesExceededException\n",
    "except ImportError:\n",
    "    try:\n",
    "        from scholarly._proxy_generator import MaxTriesExceededException\n",
    "    except ImportError:\n",
    "        MaxTriesExceededException = Exception\n",
    "        logging.warning(\"Could not import specific MaxTriesExceededException from scholarly. Rate limit errors might not be caught precisely.\")\n",
    "\n",
    "MAX_SEARCH_RESULTS_TO_CHECK = 10\n",
    "NAME_SIMILARITY_THRESHOLD = 0.85\n",
    "SINGLE_RESULT_SIMILARITY_THRESHOLD = 0.75\n",
    "\n",
    "MAX_PUBS_TO_PROCESS = 100\n",
    "TOP_N_PUBS_TO_SAVE_IN_REPORT = 100\n",
    "OUTPUT_DIR = \"L-index calculations\"\n",
    "\n",
    "logger = logging.getLogger()\n",
    "\n",
    "LARGE_GROUP_KEYWORDS = [\"consortium\", \"consortia\", \"group\", \"collaboration\", \"society\", \"association\", \"initiative\", \"network\", \"committee\", \"investigators\", \"program\", \"programm\", \"team\", \"atlas\", \"international\"]\n",
    "\n",
    "log_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "if logger.hasHandlers():\n",
    "    logger.handlers.clear()\n",
    "logger.setLevel(logging.INFO)\n",
    "stream_handler = logging.StreamHandler()\n",
    "stream_handler.setFormatter(log_formatter)\n",
    "logger.addHandler(stream_handler)\n",
    "\n",
    "def sanitize_filename(name):\n",
    "    s = re.sub(r'[^\\w\\-\\.]+', '_', name)\n",
    "    s = re.sub(r'_+', '_', s).strip('_')\n",
    "    return s if s else \"invalid_name\"\n",
    "\n",
    "def count_authors(author_string):\n",
    "    if not author_string:\n",
    "        return None\n",
    "    if isinstance(author_string, (list, tuple)):\n",
    "        author_string = ' and '.join(map(str, author_string))\n",
    "        if not author_string:\n",
    "            return None\n",
    "\n",
    "    author_string_lower = author_string.lower()\n",
    "    author_string_padded = f' {author_string_lower} '\n",
    "\n",
    "    temp_string = author_string_lower.replace(' and ', ',').replace(';', ',')\n",
    "    parts = [part.strip() for part in temp_string.split(',') if part.strip()]\n",
    "    base_count = max(1, len(parts))\n",
    "\n",
    "    additional_count = 0\n",
    "    if ' et al' in author_string_padded: additional_count += 3\n",
    "    found_large_group = False\n",
    "    for keyword in LARGE_GROUP_KEYWORDS:\n",
    "        if f' {keyword} ' in author_string_padded:\n",
    "            found_large_group = True; break\n",
    "    if found_large_group: additional_count += 50\n",
    "    return base_count + additional_count\n",
    "\n",
    "def encode_string_for_pdf(text):\n",
    "    if text is None:\n",
    "        return \"\"\n",
    "    return str(text)\n",
    "\n",
    "\n",
    "class PDF(FPDF):\n",
    "    def header(self):\n",
    "        pass\n",
    "\n",
    "    def chapter_title(self, title):\n",
    "        self.set_font('DejaVu', 'B', 12)\n",
    "        safe_title = encode_string_for_pdf(title)\n",
    "        self.cell(0, 8, safe_title, border=0, align='L', new_x=XPos.LMARGIN, new_y=YPos.NEXT)\n",
    "        self.ln(2)\n",
    "\n",
    "    def chapter_body(self, data, is_list=False):\n",
    "        self.set_font('DejaVu', '', 10)\n",
    "        if is_list:\n",
    "            for item in data:\n",
    "                safe_item = encode_string_for_pdf(f\"- {item}\")\n",
    "                self.multi_cell(0, 5, safe_item, new_x=XPos.LMARGIN, new_y=YPos.NEXT)\n",
    "        else:\n",
    "            safe_data = encode_string_for_pdf(data)\n",
    "            self.multi_cell(0, 5, safe_data, new_x=XPos.LMARGIN, new_y=YPos.NEXT)\n",
    "        self.ln()\n",
    "\n",
    "    def key_value(self, key, value, is_link=False, link_url=\"\"):\n",
    "        self.set_font('DejaVu', 'B', 10)\n",
    "        key_width = 30\n",
    "        safe_key = encode_string_for_pdf(key + \":\")\n",
    "        self.cell(key_width, 6, safe_key, border=0, align='L', new_x=XPos.RIGHT, new_y=YPos.TOP)\n",
    "        self.set_font('DejaVu', '', 10)\n",
    "        current_x = self.get_x()\n",
    "        if value:\n",
    "            processed_value = encode_string_for_pdf(value)\n",
    "            if is_link and link_url:\n",
    "                 self.set_text_color(0, 0, 255); self.set_font('', 'U')\n",
    "                 self.set_x(current_x)\n",
    "                 self.write(6, processed_value, link_url)\n",
    "                 self.set_font('', ''); self.set_text_color(0, 0, 0)\n",
    "                 self.ln(6)\n",
    "            else:\n",
    "                 self.set_x(current_x)\n",
    "                 value_width = self.w - self.l_margin - self.r_margin - key_width\n",
    "                 self.multi_cell(value_width, 6, processed_value, border=0, align='L', new_x=XPos.LMARGIN, new_y=YPos.NEXT)\n",
    "        else:\n",
    "             self.set_x(current_x)\n",
    "             self.cell(0, 6, \"N/A\", border=0, align='L', new_x=XPos.LMARGIN, new_y=YPos.NEXT)\n",
    "\n",
    "    def publication_table(self, header, data):\n",
    "        self.set_font('DejaVu', 'B', 8) # Changed from Helvetica\n",
    "        total_width = self.w - 2 * self.l_margin\n",
    "        base_pcts = [0.04, 0.08, 0.08, 0.08, 0.05, 0.06]\n",
    "        min_widths = [8, 12, 12, 12, 8, 10]\n",
    "        col_widths = [max(min_w, total_width * pct) for min_w, pct in zip(min_widths, base_pcts)]\n",
    "        title_width = max(20, total_width - sum(col_widths))\n",
    "        col_widths.append(title_width)\n",
    "        current_total = sum(col_widths)\n",
    "        if current_total > total_width:\n",
    "            scale_factor = total_width / current_total\n",
    "            col_widths = [w * scale_factor for w in col_widths]\n",
    "\n",
    "        for i, title in enumerate(header):\n",
    "            align_val = Align.C\n",
    "            new_x_pos = XPos.RIGHT if i < len(header) - 1 else XPos.LMARGIN\n",
    "            new_y_pos = YPos.TOP if i < len(header) - 1 else YPos.NEXT\n",
    "            header_text = encode_string_for_pdf(title)\n",
    "            self.cell(col_widths[i], 7, header_text, border=1, align=align_val, new_x=new_x_pos, new_y=new_y_pos)\n",
    "\n",
    "        self.set_font('DejaVu', '', 8)\n",
    "        for row in data:\n",
    "            y_start = self.get_y()\n",
    "\n",
    "            title_chars_per_line_est = col_widths[6] * 2 if col_widths[6] > 0 else 1\n",
    "            title_lines = math.ceil(len(str(row[6])) / title_chars_per_line_est) if title_chars_per_line_est > 0 else 1\n",
    "            needed_height = max(5, title_lines * 4)\n",
    "\n",
    "            if y_start + needed_height > self.h - self.b_margin:\n",
    "                self.add_page()\n",
    "                self.set_font('DejaVu', 'B', 8)\n",
    "                for i_h, title_h in enumerate(header):\n",
    "                    align_val = Align.C\n",
    "                    new_x_pos = XPos.RIGHT if i_h < len(header) - 1 else XPos.LMARGIN\n",
    "                    new_y_pos = YPos.TOP if i_h < len(header) - 1 else YPos.NEXT\n",
    "                    header_text_new = encode_string_for_pdf(title_h)\n",
    "                    self.cell(col_widths[i_h], 7, header_text_new, border=1, align=align_val, new_x=new_x_pos, new_y=new_y_pos)\n",
    "                self.set_font('DejaVu', '', 8)\n",
    "                y_start = self.get_y()\n",
    "\n",
    "            current_max_y = y_start\n",
    "            align_map = [Align.R, Align.R, Align.R, Align.R, Align.R, Align.C, Align.L]\n",
    "            current_x = self.l_margin\n",
    "            for idx, (cell_data, width, align_val) in enumerate(zip(row, col_widths, align_map)):\n",
    "                self.set_xy(current_x, y_start)\n",
    "                processed_data = encode_string_for_pdf(cell_data)\n",
    "                self.multi_cell(width, 5, processed_data, border=0, align=align_val)\n",
    "                current_max_y = max(current_max_y, self.get_y())\n",
    "                current_x += width\n",
    "\n",
    "            self.set_y(y_start)\n",
    "            x = self.l_margin\n",
    "            self.line(x, y_start, x, current_max_y)\n",
    "            for w in col_widths:\n",
    "                x += w\n",
    "                self.line(x, y_start, x, current_max_y)\n",
    "            self.line(self.l_margin, current_max_y, self.w - self.r_margin, current_max_y)\n",
    "            self.set_y(current_max_y)\n",
    "\n",
    "\n",
    "def save_results_to_pdf(filename, author_details, l_index, processed_count, total_pubs_reported, top_pubs, was_rate_limited, skips_summary_data):\n",
    "    try:\n",
    "        pdf = PDF(orientation='L', unit='mm', format='A4')\n",
    "\n",
    "        try:\n",
    "            pdf.add_font('DejaVu', '', 'DejaVuSans.ttf', uni=True)\n",
    "            pdf.add_font('DejaVu', 'B', 'DejaVuSans-Bold.ttf', uni=True)\n",
    "            pdf.add_font('DejaVu', 'I', 'DejaVuSans-Oblique.ttf', uni=True)\n",
    "            pdf.add_font('DejaVu', 'BI', 'DejaVuSans-BoldOblique.ttf', uni=True)\n",
    "        except RuntimeError as e:\n",
    "            logger.error(f\"Could not load DejaVu font: {e}. Cyrillic characters may not display correctly.\")\n",
    "            logger.error(\"Please ensure DejaVuSans.ttf, DejaVuSans-Bold.ttf, DejaVuSans-Oblique.ttf, and DejaVuSans-BoldOblique.ttf are in the script's directory or provide a full path.\")\n",
    "            logger.error(\"Falling back to Helvetica; Cyrillic support will be MISSING.\")\n",
    "\n",
    "        pdf.add_page()\n",
    "\n",
    "        author_name = author_details.get('name', 'N/A')\n",
    "        pdf.set_font('DejaVu', 'B', 14)\n",
    "        pdf.multi_cell(0, 10, encode_string_for_pdf(author_name), border=0, align='L', new_x=XPos.LMARGIN, new_y=YPos.NEXT)\n",
    "\n",
    "        pdf.set_font('DejaVu', '', 10)\n",
    "        affiliation = author_details.get('affiliation')\n",
    "        if affiliation:\n",
    "            pdf.multi_cell(0, 5, encode_string_for_pdf(affiliation), align='L', new_x=XPos.LMARGIN, new_y=YPos.NEXT)\n",
    "        else: pdf.ln(1)\n",
    "\n",
    "        interests = author_details.get('interests')\n",
    "        if interests:\n",
    "            interests_str = \", \".join(interests)\n",
    "            pdf.multi_cell(0, 5, encode_string_for_pdf(interests_str), align='L', new_x=XPos.LMARGIN, new_y=YPos.NEXT)\n",
    "        else: pdf.ln(1)\n",
    "\n",
    "        profile_url = None\n",
    "        scholar_id = author_details.get('scholar_id')\n",
    "        if scholar_id:\n",
    "            profile_url = f\"https://scholar.google.com/citations?user={scholar_id}\"\n",
    "            pdf.set_text_color(0, 0, 255); pdf.set_font('', 'U')\n",
    "            pdf.cell(0, 5, encode_string_for_pdf(profile_url), link=profile_url, align='L', new_x=XPos.LMARGIN, new_y=YPos.NEXT)\n",
    "            pdf.set_font('', ''); pdf.set_text_color(0, 0, 0)\n",
    "        else: pdf.ln(1)\n",
    "\n",
    "        pdf.ln(5)\n",
    "\n",
    "        if was_rate_limited:\n",
    "            pdf.set_text_color(255, 0, 0); pdf.set_font('DejaVu', 'B', 10)\n",
    "            pdf.multi_cell(0, 5, encode_string_for_pdf(\"*** WARNING: Processing aborted or affected by Google Scholar rate limit (429 errors). Results may be based on incomplete data. ***\"), border=0, align='L', new_x=XPos.LMARGIN, new_y=YPos.NEXT)\n",
    "            pdf.set_text_color(0, 0, 0); pdf.ln(2)\n",
    "\n",
    "        pdf.key_value(\"L-index\", f\"{l_index:.2f}\" if l_index is not None else \"Error\")\n",
    "\n",
    "        pdf.set_font('DejaVu', 'I', 9)\n",
    "        current_date_str = datetime.datetime.now().strftime(\"%d %B %Y\")\n",
    "        calc_basis_str = f\"Calculated on {current_date_str} based on the {total_pubs_reported} most cited publications fetched\"\n",
    "        pdf.multi_cell(0, 5, encode_string_for_pdf(calc_basis_str), align='L', new_x=XPos.LMARGIN, new_y=YPos.NEXT)\n",
    "        pdf.set_font('DejaVu', '', 10)\n",
    "        pdf.ln(1)\n",
    "\n",
    "        pdf.ln(3)\n",
    "        total_skipped_in_pdf = sum(\n",
    "            count for reason, count in skips_summary_data.items()\n",
    "            if reason != 'processing_halted_by_rate_limit' and count > 0\n",
    "        )\n",
    "        halted_early_count_pdf = skips_summary_data.get('processing_halted_by_rate_limit', 0)\n",
    "\n",
    "        if total_skipped_in_pdf > 0 or halted_early_count_pdf > 0:\n",
    "            pdf.set_font('DejaVu', 'B', 10)\n",
    "            pdf.cell(0, 6, \"Publication Processing Notes:\", border=0, align='L', new_x=XPos.LMARGIN, new_y=YPos.NEXT)\n",
    "            pdf.set_font('DejaVu', '', 9)\n",
    "\n",
    "            if total_skipped_in_pdf > 0:\n",
    "                pdf.multi_cell(0, 5, encode_string_for_pdf(f\"- Publications skipped due to missing/invalid data: {total_skipped_in_pdf}\"), new_x=XPos.LMARGIN, new_y=YPos.NEXT)\n",
    "                for reason, count in skips_summary_data.items():\n",
    "                    if count > 0 and reason != 'processing_halted_by_rate_limit':\n",
    "                        reason_text = reason.replace('_', ' ')\n",
    "                        pdf.multi_cell(0, 4, encode_string_for_pdf(f\"    - {count} due to: {reason_text}\"), new_x=XPos.LMARGIN, new_y=YPos.NEXT)\n",
    "            \n",
    "            if halted_early_count_pdf > 0:\n",
    "                pdf.multi_cell(0, 5, encode_string_for_pdf(f\"- Publications not processed/completed due to rate limit or early stop: {halted_early_count_pdf}\"), new_x=XPos.LMARGIN, new_y=YPos.NEXT)\n",
    "            pdf.ln(3)\n",
    "\n",
    "        pdf.ln(5)\n",
    "\n",
    "        pubs_to_show_in_table = top_pubs[:TOP_N_PUBS_TO_SAVE_IN_REPORT]\n",
    "        pdf.chapter_title(f\"Top {len(pubs_to_show_in_table)} Contributing Publications (among {processed_count} successfully processed)\")\n",
    "\n",
    "\n",
    "        if not pubs_to_show_in_table:\n",
    "            pdf.cell(0, 6, \"(No publications processed had a contribution score > 0 or processing was stopped/encountered issues)\", border=0, align='L', new_x=XPos.LMARGIN, new_y=YPos.NEXT)\n",
    "        else:\n",
    "            header = ['#', 'Score', 'Cites', 'Authors', 'Age', 'Year', 'Title']\n",
    "            table_data = []\n",
    "            for i, pub_data in enumerate(pubs_to_show_in_table):\n",
    "                rank_str = f\"{i+1}.\"\n",
    "                term_str = f\"{pub_data['term']:.1f}\"\n",
    "                c_str = str(pub_data['citations'])\n",
    "                a_str = str(pub_data['authors'])\n",
    "                y_str = str(pub_data['age'])\n",
    "                yr_str = str(pub_data['year'])\n",
    "                title_str = str(pub_data['title'])[:150] + ('...' if len(str(pub_data['title'])) > 150 else '')\n",
    "                table_data.append([rank_str, term_str, c_str, a_str, y_str, yr_str, title_str])\n",
    "            pdf.publication_table(header, table_data)\n",
    "\n",
    "        pdf.ln(10)\n",
    "        pdf.set_font('DejaVu','', 8)\n",
    "        current_year = datetime.datetime.now().year\n",
    "        footer1 = f\"L-index Calculator by Aleksey V. Belikov, 2025\"\n",
    "        footer2 = f\"L-index concept by Aleksey V. Belikov & Vitaly V. Belikov, 2015\"\n",
    "        pdf.cell(0, 5, encode_string_for_pdf(footer1), align='L', new_x=XPos.LMARGIN, new_y=YPos.NEXT)\n",
    "        pdf.cell(0, 5, encode_string_for_pdf(footer2), align='L', new_x=XPos.LMARGIN, new_y=YPos.NEXT)\n",
    "\n",
    "        pdf.set_font('DejaVu', 'B', 8)\n",
    "        pdf.cell(0, 5, \" \", align='L', new_x=XPos.LMARGIN, new_y=YPos.NEXT)\n",
    "        pdf.set_font('DejaVu','', 8)\n",
    "        citation_text = \"Belikov AV and Belikov VV. A citation-based, author- and age-normalized, logarithmic index for evaluation of individual researchers independently of publication counts. F1000Research 2015, 4:884\"\n",
    "        citation_url = \"https://doi.org/10.12688/f1000research.7070.1\"\n",
    "        pdf.multi_cell(0, 4, encode_string_for_pdf(citation_text), align='L', new_x=XPos.LMARGIN, new_y=YPos.NEXT)\n",
    "        pdf.set_text_color(0, 0, 255); pdf.set_font('', 'U')\n",
    "        pdf.cell(0, 4, encode_string_for_pdf(f\"({citation_url})\"), align='L', link=citation_url, new_x=XPos.LMARGIN, new_y=YPos.NEXT)\n",
    "        pdf.set_text_color(0, 0, 0); pdf.set_font('', '')\n",
    "\n",
    "        pdf.output(filename)\n",
    "        logger.info(f\"Results successfully saved to PDF: {filename}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to generate PDF report: {e}\", exc_info=True)\n",
    "        print(f\"\\nError: Could not generate PDF report '{filename}'. Check logs.\")\n",
    "\n",
    "\n",
    "def calculate_l_index(author_name_or_id, max_pubs_limit):\n",
    "    preliminary_index_I = 0.0\n",
    "    processed_pubs_count = 0\n",
    "    author_details = {'name': 'N/A', 'affiliation': None, 'interests': [], 'scholar_id': None, 'citedby': 'N/A'}\n",
    "    publication_details = []\n",
    "    rate_limited = False\n",
    "    total_pubs_reported = 0\n",
    "    i = -1\n",
    "    \n",
    "    skipped_details = {\n",
    "        'author_field_empty': 0,\n",
    "        'pub_year_missing': 0,\n",
    "        'pub_year_invalid_format_or_range': 0,\n",
    "        'processing_halted_by_rate_limit': 0,\n",
    "        'other_critical_error_per_pub': 0\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        logger.info(f\"Searching for author: {author_name_or_id}\")\n",
    "        is_id_search = bool(re.match(r'^[\\w-]{12}$', author_name_or_id))\n",
    "        author_to_process = None\n",
    "\n",
    "        if is_id_search:\n",
    "            try:\n",
    "                author_stub = scholarly.scholarly.search_author_id(author_name_or_id, filled=False)\n",
    "                if not author_stub:\n",
    "                    raise ValueError(f\"No author found for ID '{author_name_or_id}'.\")\n",
    "                author_details['scholar_id'] = author_stub.get('scholar_id')\n",
    "                author_details['name'] = author_stub.get('name', 'Name Not Found')\n",
    "                author_to_process = author_stub\n",
    "                if not author_details['scholar_id']: raise ValueError(\"Author ID search returned result without scholar_id.\")\n",
    "                logger.info(f\"Found author by ID: {author_details['name']} (ID: {author_details['scholar_id']})\")\n",
    "            except MaxTriesExceededException as rt_err: logger.error(f\"Rate limit during author ID lookup: {rt_err}. Aborting.\"); rate_limited = True; return None, author_details, 0.0, 0, 0, [], rate_limited, skipped_details\n",
    "            except StopIteration:\n",
    "                 logger.error(f\"No author found for ID '{author_name_or_id}'. ID might be invalid or profile private/removed.\")\n",
    "                 return None, author_details, 0.0, 0, 0, [], rate_limited, skipped_details\n",
    "            except Exception as e: logger.error(f\"Failed during author ID lookup: {e}\", exc_info=False); return None, author_details, 0.0, 0, 0, [], rate_limited, skipped_details\n",
    "        else:\n",
    "             potential_authors = []\n",
    "             try:\n",
    "                  search_query = scholarly.scholarly.search_author(author_name_or_id)\n",
    "                  for idx in range(MAX_SEARCH_RESULTS_TO_CHECK):\n",
    "                     try:\n",
    "                         auth = next(search_query, None)\n",
    "                         if auth is None: break\n",
    "                         if auth and 'scholar_id' in auth: potential_authors.append(auth)\n",
    "                         elif auth: logger.warning(f\"Search result missing 'scholar_id': {auth.get('name', 'N/A')}\")\n",
    "                     except StopIteration: break\n",
    "                     except MaxTriesExceededException as rt_err_inner: logger.error(f\"Rate limit during author search iteration {idx+1}: {rt_err_inner}. Stopping search.\"); rate_limited = True; break\n",
    "                     except Exception as e_inner: logger.error(f\"Error during author search iteration {idx+1}: {e_inner}. Stopping search.\"); break\n",
    "                  logger.info(f\"Found {len(potential_authors)} potential author(s) with IDs.\")\n",
    "             except MaxTriesExceededException as rt_err: logger.error(f\"Rate limit during initial author search setup: {rt_err}. Aborting.\"); rate_limited = True\n",
    "             except StopIteration: logger.info(f\"Found {len(potential_authors)} potential author(s) with IDs (StopIteration caught).\")\n",
    "             except Exception as e: logger.error(f\"Error during author search setup: {e}\", exc_info=False); potential_authors = []\n",
    "\n",
    "             if rate_limited: return None, author_details, 0.0, 0, 0, [], rate_limited, skipped_details\n",
    "             if not potential_authors: logger.error(f\"Author '{author_name_or_id}' not found or no suitable matches retrieved.\"); return None, author_details, 0.0, 0, 0, [], rate_limited, skipped_details\n",
    "\n",
    "             best_match_author = None; highest_ratio = 0.0; query_lower = author_name_or_id.lower()\n",
    "             logger.info(\"Evaluating potential matches:\")\n",
    "             for pa in potential_authors:\n",
    "                 name_lower = pa.get('name', '').lower();\n",
    "                 if not name_lower: continue\n",
    "                 ratio = SequenceMatcher(None, query_lower, name_lower).ratio()\n",
    "                 logger.info(f\"  - Candidate: '{pa.get('name', 'N/A')}', ID: {pa.get('scholar_id', 'N/A')}, Aff: {pa.get('affiliation', 'N/A')}, Ratio: {ratio:.3f}\")\n",
    "                 if ratio > highest_ratio:\n",
    "                     highest_ratio = ratio\n",
    "                     best_match_author = pa\n",
    "                 elif ratio == highest_ratio and best_match_author:\n",
    "                     logger.info(f\"  - Note: Equal ratio {ratio:.3f} found for '{pa.get('name', 'N/A')}' and '{best_match_author.get('name', 'N/A')}'. Keeping first best match.\")\n",
    "                     pass\n",
    "\n",
    "             selected_author_final = None\n",
    "             effective_threshold = NAME_SIMILARITY_THRESHOLD\n",
    "             if len(potential_authors) == 1:\n",
    "                 effective_threshold = SINGLE_RESULT_SIMILARITY_THRESHOLD\n",
    "                 logger.info(f\"Only one result found. Using adjusted threshold for selection: {effective_threshold:.2f}\")\n",
    "\n",
    "             if best_match_author and highest_ratio >= effective_threshold:\n",
    "                 selected_author_final = best_match_author\n",
    "                 logger.info(f\"Selected author based on highest ratio >= threshold: {selected_author_final['name']} (Ratio: {highest_ratio:.3f})\")\n",
    "             else:\n",
    "                 logger.warning(f\"Could not find a confident match. Best match '{best_match_author.get('name', 'N/A') if best_match_author else 'None'}' had ratio {highest_ratio:.3f} (Threshold: {effective_threshold:.2f}).\")\n",
    "                 logger.error(f\"Failed to identify a sufficiently similar author match.\")\n",
    "                 return None, author_details, 0.0, 0, 0, [], rate_limited, skipped_details\n",
    "\n",
    "             author_to_process = selected_author_final\n",
    "             author_details['scholar_id'] = author_to_process.get('scholar_id')\n",
    "             author_details['name'] = author_to_process.get('name', 'Name Not Found')\n",
    "\n",
    "        if not author_to_process or not author_details.get('scholar_id'):\n",
    "            logger.error(\"Author selection process failed to yield a valid author object or ID.\")\n",
    "            return None, author_details, 0.0, 0, 0, [], rate_limited, skipped_details\n",
    "\n",
    "        logger.info(f\"Fetching full profile details for {author_details.get('name', 'N/A')} (ID: {author_details.get('scholar_id')})...\")\n",
    "        author_filled_profile = None\n",
    "        try:\n",
    "            sections_to_fill = ['basics', 'indices', 'interests', 'coauthors', 'counts']\n",
    "            author_filled_profile = scholarly.scholarly.fill(author_to_process, sections=sections_to_fill)\n",
    "\n",
    "            author_details['name'] = author_filled_profile.get('name', author_details.get('name'))\n",
    "            author_details['affiliation'] = author_filled_profile.get('affiliation', author_details.get('affiliation'))\n",
    "            author_details['interests'] = author_filled_profile.get('interests', author_details.get('interests', []))\n",
    "            author_details['citedby'] = author_filled_profile.get('citedby', author_details.get('citedby', 'N/A'))\n",
    "\n",
    "            logger.info(f\"Successfully fetched profile details. Name: '{author_details['name']}', Affiliation: '{author_details.get('affiliation', 'N/A')}', Total citations reported: {author_details['citedby']}\")\n",
    "\n",
    "        except MaxTriesExceededException as rt_err:\n",
    "            logger.error(f\"Rate limit occurred while fetching full profile details: {rt_err}. Proceeding with potentially incomplete author info (using stub data if available).\")\n",
    "            rate_limited = True\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error filling author profile: {e}. Proceeding with potentially incomplete author info.\", exc_info=False)\n",
    "\n",
    "        logger.info(f\"Fetching initial publication list (sorted by citedby, limit {max_pubs_limit})...\")\n",
    "        initial_pubs = []\n",
    "        try:\n",
    "            author_obj_for_pubs = author_filled_profile if author_filled_profile else author_to_process\n",
    "            if 'publications' not in author_obj_for_pubs:\n",
    "                logger.info(\"Filling publications section...\")\n",
    "                author_pubs_filled = scholarly.scholarly.fill(\n",
    "                    author_obj_for_pubs,\n",
    "                    sections=['publications'],\n",
    "                    sortby='citedby',\n",
    "                    publication_limit=max_pubs_limit\n",
    "                )\n",
    "            else:\n",
    "                 logger.info(\"Publications section already present, using existing data (up to limit).\")\n",
    "                 author_pubs_filled = author_obj_for_pubs\n",
    "\n",
    "            if not author_pubs_filled or 'publications' not in author_pubs_filled or author_pubs_filled['publications'] is None:\n",
    "                initial_pubs = []\n",
    "            else:\n",
    "                initial_pubs = author_pubs_filled.get('publications', [])[:max_pubs_limit]\n",
    "\n",
    "        except MaxTriesExceededException as rt_err:\n",
    "            logger.error(f\"Rate limit occurred while fetching publication list: {rt_err}. Aborting calculation.\")\n",
    "            rate_limited = True\n",
    "            return None, author_details, 0.0, 0, 0, [], rate_limited, skipped_details\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error fetching publication list: {e}\", exc_info=False)\n",
    "            return None, author_details, 0.0, 0, 0, [], rate_limited, skipped_details\n",
    "\n",
    "        total_pubs_reported = len(initial_pubs)\n",
    "        if not initial_pubs and not rate_limited:\n",
    "            logger.warning(f\"No publications found for author {author_details.get('name')}. L-index will be 0.\")\n",
    "            return 0.0, author_details, 0.0, 0, total_pubs_reported, [], rate_limited, skipped_details\n",
    "\n",
    "        pubs_to_process = initial_pubs\n",
    "        num_selected = len(pubs_to_process)\n",
    "        logger.info(f\"Fetched {num_selected} publications (limit was {max_pubs_limit}). Starting processing...\")\n",
    "        current_year = datetime.datetime.now().year\n",
    "\n",
    "        for i, pub_stub in enumerate(pubs_to_process):\n",
    "            if rate_limited and not skipped_details['processing_halted_by_rate_limit']:\n",
    "                skipped_details['processing_halted_by_rate_limit'] = num_selected - i\n",
    "                logger.warning(f\"Skipping remaining {num_selected - i} publications processing due to rate limit flag set before or during this pub's processing.\")\n",
    "                break\n",
    "            if skipped_details['processing_halted_by_rate_limit'] > 0:\n",
    "                break\n",
    "\n",
    "            pub_title_guess = pub_stub.get('bib', {}).get('title', 'Unknown Title')\n",
    "            logger.info(f\"Processing pub {i+1}/{num_selected}: '{pub_title_guess[:60]}...'\")\n",
    "\n",
    "            try:\n",
    "                pub = None\n",
    "                bib = {}\n",
    "                author_str = ''\n",
    "                citations = 0\n",
    "\n",
    "                try:\n",
    "                    pub = scholarly.scholarly.fill(pub_stub)\n",
    "                    bib = pub.get('bib', {})\n",
    "                except MaxTriesExceededException as rt_err:\n",
    "                    logger.error(f\"Rate limit hit while filling details for pub {i+1} ('{pub_title_guess[:50]}...'): {rt_err}. Aborting further publication processing.\")\n",
    "                    rate_limited = True\n",
    "                    skipped_details['processing_halted_by_rate_limit'] = (num_selected - i)\n",
    "                    break\n",
    "                except Exception as fill_err:\n",
    "                    logger.warning(f\"Failed to fill details for pub {i+1} ('{pub_title_guess[:50]}...'): {fill_err}. Using stub data for checks.\", exc_info=False)\n",
    "                    pub = pub_stub\n",
    "                    bib = pub.get('bib', {})\n",
    "\n",
    "                title = bib.get('title', 'Title Not Available')\n",
    "\n",
    "                author_str = bib.get('author', '')\n",
    "                if not author_str:\n",
    "                    logger.warning(f\"Skipping pub {i+1} ('{title[:50]}...') due to missing or empty 'author' field.\")\n",
    "                    skipped_details['author_field_empty'] += 1\n",
    "                    continue\n",
    "\n",
    "                pub_year_str = bib.get('pub_year', None)\n",
    "                if pub_year_str is None:\n",
    "                    logger.warning(f\"Skipping pub {i+1} ('{title[:50]}...') due to missing 'pub_year' field.\")\n",
    "                    skipped_details['pub_year_missing'] += 1\n",
    "                    continue\n",
    "                \n",
    "                pub_year = 0\n",
    "                try:\n",
    "                    pub_year = int(pub_year_str)\n",
    "                    if not (1800 <= pub_year <= current_year + 2):\n",
    "                        logger.warning(f\"Skipping pub {i+1} ('{title[:50]}...') due to out-of-range year: {pub_year}.\")\n",
    "                        skipped_details['pub_year_invalid_format_or_range'] += 1\n",
    "                        continue\n",
    "                except ValueError:\n",
    "                    logger.warning(f\"Skipping pub {i+1} ('{title[:50]}...') due to non-integer year format: '{pub_year_str}'.\")\n",
    "                    skipped_details['pub_year_invalid_format_or_range'] += 1\n",
    "                    continue\n",
    "\n",
    "                citations_val = pub.get('num_citations')\n",
    "                if citations_val is None and pub is not pub_stub:\n",
    "                    citations_val = pub_stub.get('num_citations')\n",
    "\n",
    "                if citations_val is None:\n",
    "                    citations = 0\n",
    "                else:\n",
    "                    citations = int(citations_val)\n",
    "\n",
    "                num_authors_temp = count_authors(author_str)\n",
    "                num_authors = 1\n",
    "                if num_authors_temp is None:\n",
    "                    logger.warning(f\"Could not reliably count authors for pub {i+1} ('{title[:50]}...') from non-empty string '{author_str[:30]}...'. Assuming 1 author.\")\n",
    "                else:\n",
    "                    num_authors = num_authors_temp\n",
    "                \n",
    "                age = max(1, current_year - pub_year + 1)\n",
    "                denominator = num_authors * age\n",
    "                term = citations / denominator if denominator > 0 else 0\n",
    "\n",
    "                pub_data = {\n",
    "                    'term': term, 'title': title, 'year': pub_year,\n",
    "                    'citations': citations, 'authors': num_authors, 'age': age\n",
    "                }\n",
    "                publication_details.append(pub_data)\n",
    "                preliminary_index_I += term\n",
    "                processed_pubs_count += 1\n",
    "\n",
    "                if (processed_pubs_count % 25 == 0) and processed_pubs_count > 0:\n",
    "                    logger.info(f\"Processed {processed_pubs_count} valid publications so far...\")\n",
    "\n",
    "            except Exception as e:\n",
    "                pub_title_for_error = pub_stub.get('bib', {}).get('title', 'Unknown Title')\n",
    "                logger.error(f\"Critical error processing pub {i+1} ('{pub_title_for_error[:50]}...'): {e}. Skipping this publication.\", exc_info=False)\n",
    "                skipped_details['other_critical_error_per_pub'] += 1\n",
    "\n",
    "        if any(skipped_details.values()):\n",
    "            logger.info(\"--- Publication Skipping & Processing Summary ---\")\n",
    "            total_pubs_iterated_before_stop = i + 1 if i != -1 else 0\n",
    "            \n",
    "            if pubs_to_process and total_pubs_iterated_before_stop == 0 and skipped_details.get('processing_halted_by_rate_limit',0) == num_selected:\n",
    "                 pass\n",
    "            elif num_selected > 0 :\n",
    "                 logger.info(f\"Attempted to process up to publication {total_pubs_iterated_before_stop} out of {num_selected} fetched.\")\n",
    "\n",
    "            for reason, count in skipped_details.items():\n",
    "                if count > 0:\n",
    "                    reason_text = reason.replace('_', ' ')\n",
    "                    if reason == 'processing_halted_by_rate_limit':\n",
    "                        logger.warning(f\"{count} publications were not processed or completed due to: {reason_text}\")\n",
    "                    else:\n",
    "                        logger.info(f\"Skipped {count} pubs (among those attempted) due to: {reason_text}\")\n",
    "\n",
    "        l_index = math.log(preliminary_index_I + 1) if preliminary_index_I > 0 else 0.0\n",
    "\n",
    "        logger.info(\"Sorting processed publications by contribution score (term)...\")\n",
    "        sorted_contributors = sorted(publication_details, key=lambda p: p['term'], reverse=True)\n",
    "\n",
    "        positive_term_contributors = [p for p in sorted_contributors if p['term'] > 0]\n",
    "        logger.info(f\"Identified {len(positive_term_contributors)} processed publications with a contribution score > 0.\")\n",
    "\n",
    "        top_contributing_list = sorted_contributors\n",
    "\n",
    "        if rate_limited:\n",
    "            logger.warning(\"Calculation finished BUT was affected or aborted early due to Google Scholar rate limiting.\")\n",
    "        else:\n",
    "            logger.info(f\"Calculation process completed. Processed {processed_pubs_count} publications successfully.\")\n",
    "            if i + 1 < num_selected and not skipped_details.get('processing_halted_by_rate_limit'):\n",
    "                 logger.warning(f\"Processing loop did not complete all {num_selected} fetched publications (stopped after attempting pub {i+1}). This might indicate an error not caught as rate limit, or all remaining pubs were skipped for data reasons.\")\n",
    "\n",
    "        return l_index, author_details, preliminary_index_I, processed_pubs_count, total_pubs_reported, top_contributing_list, rate_limited, skipped_details\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An unexpected critical error occurred during the main calculation process: {e}\", exc_info=True)\n",
    "        return None, author_details, preliminary_index_I, processed_pubs_count, total_pubs_reported, [], rate_limited, skipped_details\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"-\" * 60)\n",
    "    print(\"L-index Calculator by Aleksey V. Belikov\")\n",
    "    print(\"-\" * 60)\n",
    "    max_pubs_limit = MAX_PUBS_TO_PROCESS\n",
    "    print(\"-\" * 60)\n",
    "    print(\"IMPORTANT NOTES:\")\n",
    "    print(\"1. Results are entirely dependent on the accuracy, completeness and public availability of the scientist's Google Scholar profile\")\n",
    "    print(\"2. While the script attempts to find the best match for the scientist's name, errors can occur, especially for common names\")\n",
    "    print(\"3. Check the affiliation, keywords and top publications in the log or output pdf to verify that the correct scientist has been identified\")\n",
    "    print(\"4. Using the Google Scholar ID is recommended, it can be found at the end of the profile URL\")\n",
    "    print(\"5. Publications with missing author information or publication year will be skipped and a warning will be issued. Missing citation counts will be treated as 0 citations\")\n",
    "    print(\"6. If the script identifies one of the keywords for a large group of authors in the \"authors\" database field, it will add 50 authors to the author count, because the actual number of authors is unknown\")\n",
    "    print(f\"7. Keywords used for this are {LARGE_GROUP_KEYWORDS}\")\n",
    "    print(f\"8. Calculation is based on the {max_pubs_limit} of the scientist's most cited publications (or fewer if the scientist has less or some data were missing)\")\n",
    "    print(\"9. This can be changed by modifying MAX_PUBS_TO_PROCESS parameter in the code\")\n",
    "    print(\"10. Extensive requests can lead to temporary IP blocks (rate limiting) from Google Scholar, so it is recommended to keep MAX_PUBS_TO_PROCESS to 100 or below\")\n",
    "    print(\"11. It is recommended to wait (hours, or even a day) if you encounter persistent rate limiting, or try a different IP address or a proxy\")\n",
    "    print(\"12. Selecting too low a MAX_PUBS_TO_PROCESS value (e.g. <50) will lead to underestimation of the L-index\")\n",
    "    print(\"13. Nevertheless, we demonstrated that 50-100 most cited publications capture the bulk of the L-index, even for scientists with many hundreds of publications\")\n",
    "    print(\"14. Always compare scientists using the same MAX_PUBS_TO_PROCESS value to calculate their L-indices\")\n",
    "    print(f\"15. A PDF report including the top {TOP_N_PUBS_TO_SAVE_IN_REPORT} contributing publications will be saved in the '{OUTPUT_DIR}' directory\")\n",
    "    print(\"-\" * 60)\n",
    "    print(\"Enter Author Name or Google Scholar ID in a pop-up window\")\n",
    "\n",
    "    author_query = input(\"Enter Author Name or Google Scholar ID: \")\n",
    "\n",
    "    if not author_query:\n",
    "        print(\"No author name or ID provided. Exiting.\")\n",
    "    else:\n",
    "        l_index, author_data, prelim_I, processed_count, total_reported, top_contrib_pubs, was_rate_limited, skips_summary_data = calculate_l_index(\n",
    "            author_query,\n",
    "            max_pubs_limit\n",
    "        )\n",
    "\n",
    "        author_full_name = author_data.get('name')\n",
    "        if author_full_name is None or author_full_name == 'N/A':\n",
    "             author_full_name_display = \"N/A (Could not be determined)\"\n",
    "        else:\n",
    "             author_full_name_display = author_full_name\n",
    "\n",
    "        if was_rate_limited:\n",
    "            print(\"\\n--- WARNING: RATE LIMITED ---\")\n",
    "            print(f\"Processing may have stopped early or been affected by Google Scholar rate limits.\")\n",
    "            print(\"Results shown below might be based on INCOMPLETE data gathered before the limit was hit.\")\n",
    "            print(f\"If errors persist, please wait a significant amount of time (e.g., hours) before trying again.\")\n",
    "            if author_full_name_display.startswith(\"N/A\"):\n",
    "                 print(\"Rate limit may have occurred before the author could be definitively identified.\")\n",
    "            print(\"-\" * 60)\n",
    "\n",
    "        if author_data.get('scholar_id'):\n",
    "            if l_index is None:\n",
    "                 print(f\"\\n--- Calculation Error ---\")\n",
    "                 print(f\"Author Identified: {author_full_name_display} (ID: {author_data.get('scholar_id', 'N/A')})\")\n",
    "                 print(f\"Affiliation:       {author_data.get('affiliation', 'N/A')}\")\n",
    "                 print(f\"Could not complete L-index calculation due to errors after author identification.\")\n",
    "                 print(f\"(Successfully processed {processed_count} publications before error/stop).\")\n",
    "                 print(\"Please check the script's log output for detailed error messages and skip reasons.\")\n",
    "\n",
    "            else:\n",
    "                print(\"\\n--- Results Summary ---\")\n",
    "                if was_rate_limited: print(\"(NOTE: Results based on potentially INCOMPLETE data due to rate limiting)\")\n",
    "                print(f\"Author Identified: {author_full_name_display}\")\n",
    "                print(f\"Affiliation:       {author_data.get('affiliation', 'N/A')}\")\n",
    "                print(f\"Interests:         {', '.join(author_data.get('interests', [])) if author_data.get('interests') else 'N/A'}\")\n",
    "                scholar_id = author_data.get('scholar_id')\n",
    "                print(f\"Scholar Profile:   {'https://scholar.google.com/citations?user=' + scholar_id if scholar_id else 'N/A'}\")\n",
    "                print(f\"L-Index:           {l_index:.2f}\")\n",
    "                print(f\"Calculation Basis: {total_reported} most cited publications fetched from Google Scholar.\")\n",
    "                print(f\"Pubs Processed:    {processed_count} / {total_reported} (Fetched)\")\n",
    "\n",
    "                total_skipped_for_data_reasons = sum(\n",
    "                    count for reason, count in skips_summary_data.items()\n",
    "                    if reason != 'processing_halted_by_rate_limit' and count > 0\n",
    "                )\n",
    "                halted_by_rate_limit_count = skips_summary_data.get('processing_halted_by_rate_limit', 0)\n",
    "\n",
    "                if total_skipped_for_data_reasons > 0:\n",
    "                    print(f\"Skipped Publications (due to data issues): {total_skipped_for_data_reasons}\")\n",
    "                    for reason, count in skips_summary_data.items():\n",
    "                        if count > 0 and reason not in ['processing_halted_by_rate_limit']:\n",
    "                            print(f\"      - {count} due to: {reason.replace('_', ' ')}\")\n",
    "                \n",
    "                if halted_by_rate_limit_count > 0:\n",
    "                    print(f\"Processing Halted Early: {halted_by_rate_limit_count} publication(s) were not processed or completed due to rate limiting or other early stop.\")\n",
    "\n",
    "\n",
    "                if author_full_name and author_full_name != 'N/A':\n",
    "                    try:\n",
    "                        safe_filename_base = sanitize_filename(f\"{author_full_name}_{author_data.get('scholar_id', 'NoID')}\")\n",
    "                        status_tag = \"_RATE_LIMITED\" if was_rate_limited else \"\"\n",
    "                        date_str = datetime.date.today().isoformat()\n",
    "                        pdf_filename = os.path.join(OUTPUT_DIR, f\"{safe_filename_base}_L-Index_BasedOn{max_pubs_limit}{status_tag}_{date_str}.pdf\")\n",
    "                        os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "                        save_results_to_pdf(\n",
    "                            pdf_filename,\n",
    "                            author_data,\n",
    "                            l_index,\n",
    "                            processed_count,\n",
    "                            total_reported,\n",
    "                            top_contrib_pubs,\n",
    "                            was_rate_limited,\n",
    "                            skips_summary_data\n",
    "                        )\n",
    "                    except Exception as pdf_err:\n",
    "                        pass\n",
    "                else:\n",
    "                    logger.warning(\"Skipping PDF generation because a valid author name could not be determined for the filename.\")\n",
    "                    print(\"\\nWarning: PDF report generation skipped as author name was not fully determined.\")\n",
    "\n",
    "        elif not was_rate_limited:\n",
    "             print(\"\\n--- Author Not Found ---\")\n",
    "             print(\"Could not calculate L-index.\")\n",
    "             print(\"Reason: Author not found or no confident match identified via search.\")\n",
    "             print(\"Please check the spelling or try the Google Scholar ID if known.\")\n",
    "\n",
    "        print(\"-\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
