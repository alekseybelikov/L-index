{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scholarly\n",
    "import datetime\n",
    "import math\n",
    "import logging\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "from difflib import SequenceMatcher\n",
    "from fpdf import FPDF\n",
    "from fpdf.enums import XPos, YPos, Align\n",
    "\n",
    "try:\n",
    "    from scholarly._navigator import MaxTriesExceededException\n",
    "except ImportError:\n",
    "    try:\n",
    "        from scholarly._proxy_generator import MaxTriesExceededException\n",
    "    except ImportError:\n",
    "        MaxTriesExceededException = Exception\n",
    "        logging.warning(\"Could not import specific MaxTriesExceededException from scholarly. Rate limit errors might not be caught precisely.\")\n",
    "\n",
    "MAX_SEARCH_RESULTS_TO_CHECK = 10\n",
    "NAME_SIMILARITY_THRESHOLD = 0.85\n",
    "SINGLE_RESULT_SIMILARITY_THRESHOLD = 0.75\n",
    "\n",
    "MAX_PUBS_TO_PROCESS = 100 \n",
    "TOP_N_PUBS_TO_SAVE_IN_REPORT = 15\n",
    "OUTPUT_DIR = \"L-index calculations\"\n",
    "\n",
    "logger = logging.getLogger()\n",
    "\n",
    "LARGE_GROUP_KEYWORDS = [\"consortium\", \"consortia\", \"group\", \"collaboration\", \"society\", \"association\"]\n",
    "\n",
    "log_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "if logger.hasHandlers():\n",
    "    logger.handlers.clear()\n",
    "logger.setLevel(logging.INFO)\n",
    "stream_handler = logging.StreamHandler()\n",
    "stream_handler.setFormatter(log_formatter)\n",
    "logger.addHandler(stream_handler)\n",
    "\n",
    "def sanitize_filename(name):\n",
    "    \"\"\"Removes or replaces characters unsuitable for filenames.\"\"\"\n",
    "    s = re.sub(r'[^\\w\\-\\.]+', '_', name)\n",
    "    s = re.sub(r'_+', '_', s).strip('_')\n",
    "    return s if s else \"invalid_name\"\n",
    "\n",
    "def count_authors(author_string):\n",
    "    \"\"\"Estimates the number of authors from a string.\"\"\"\n",
    "    if not author_string:\n",
    "        return None\n",
    "    if isinstance(author_string, (list, tuple)):\n",
    "        author_string = ' and '.join(map(str, author_string))\n",
    "        if not author_string:\n",
    "            return None\n",
    "\n",
    "    author_string_lower = author_string.lower()\n",
    "    author_string_padded = f' {author_string_lower} '\n",
    "\n",
    "    temp_string = author_string_lower.replace(' and ', ',').replace(';', ',')\n",
    "    parts = [part.strip() for part in temp_string.split(',') if part.strip()]\n",
    "    base_count = max(1, len(parts))\n",
    "\n",
    "    additional_count = 0\n",
    "    if ' et al' in author_string_padded: additional_count += 3\n",
    "    found_large_group = False\n",
    "    for keyword in LARGE_GROUP_KEYWORDS:\n",
    "        if f' {keyword} ' in author_string_padded:\n",
    "            found_large_group = True; break\n",
    "    if found_large_group: additional_count += 50\n",
    "    return base_count + additional_count\n",
    "\n",
    "def encode_string_for_pdf(text):\n",
    "    \"\"\"Encodes text to latin-1, replacing unsupported characters, for PDF compatibility.\"\"\"\n",
    "    if text is None:\n",
    "        return \"\"\n",
    "    try:\n",
    "        text_str = str(text)\n",
    "        return text_str.encode('latin-1', 'replace').decode('latin-1')\n",
    "    except Exception:\n",
    "        try:\n",
    "            return str(text).encode('ascii', 'replace').decode('ascii')\n",
    "        except Exception:\n",
    "            return \"Encoding Error\"\n",
    "\n",
    "\n",
    "class PDF(FPDF):\n",
    "    def header(self):\n",
    "        pass\n",
    "\n",
    "    def chapter_title(self, title):\n",
    "        self.set_font('Helvetica', 'B', 12)\n",
    "        # Encode title safely\n",
    "        safe_title = encode_string_for_pdf(title)\n",
    "        self.cell(0, 8, safe_title, border=0, align='L', new_x=XPos.LMARGIN, new_y=YPos.NEXT)\n",
    "        self.ln(2)\n",
    "\n",
    "    def chapter_body(self, data, is_list=False):\n",
    "        self.set_font('Helvetica', '', 10)\n",
    "        if is_list:\n",
    "            for item in data:\n",
    "                safe_item = encode_string_for_pdf(f\"- {item}\")\n",
    "                self.multi_cell(0, 5, safe_item, new_x=XPos.LMARGIN, new_y=YPos.NEXT)\n",
    "        else:\n",
    "            safe_data = encode_string_for_pdf(data)\n",
    "            self.multi_cell(0, 5, safe_data, new_x=XPos.LMARGIN, new_y=YPos.NEXT)\n",
    "        self.ln()\n",
    "\n",
    "    def key_value(self, key, value, is_link=False, link_url=\"\"):\n",
    "        self.set_font('Helvetica', 'B', 10)\n",
    "        key_width = 30\n",
    "        safe_key = encode_string_for_pdf(key + \":\")\n",
    "        self.cell(key_width, 6, safe_key, border=0, align='L', new_x=XPos.RIGHT, new_y=YPos.TOP)\n",
    "        self.set_font('Helvetica', '', 10)\n",
    "        current_x = self.get_x()\n",
    "        if value:\n",
    "            processed_value = encode_string_for_pdf(value)\n",
    "            if is_link and link_url:\n",
    "                 self.set_text_color(0, 0, 255); self.set_font('', 'U')\n",
    "                 self.set_x(current_x)\n",
    "                 self.write(6, processed_value, link_url)\n",
    "                 self.set_font('', ''); self.set_text_color(0, 0, 0)\n",
    "                 self.ln(6)\n",
    "            else:\n",
    "                 self.set_x(current_x)\n",
    "                 value_width = self.w - self.l_margin - self.r_margin - key_width\n",
    "                 self.multi_cell(value_width, 6, processed_value, border=0, align='L', new_x=XPos.LMARGIN, new_y=YPos.NEXT)\n",
    "        else:\n",
    "             self.set_x(current_x)\n",
    "             self.cell(0, 6, \"N/A\", border=0, align='L', new_x=XPos.LMARGIN, new_y=YPos.NEXT)\n",
    "\n",
    "    def publication_table(self, header, data):\n",
    "        self.set_font('Helvetica', 'B', 8)\n",
    "        total_width = self.w - 2 * self.l_margin\n",
    "        base_pcts = [0.04, 0.08, 0.08, 0.08, 0.05, 0.06]\n",
    "        min_widths = [8, 12, 12, 12, 8, 10]\n",
    "        col_widths = [max(min_w, total_width * pct) for min_w, pct in zip(min_widths, base_pcts)]\n",
    "        title_width = max(20, total_width - sum(col_widths))\n",
    "        col_widths.append(title_width)\n",
    "        current_total = sum(col_widths)\n",
    "        if current_total > total_width:\n",
    "            scale_factor = total_width / current_total\n",
    "            col_widths = [w * scale_factor for w in col_widths]\n",
    "\n",
    "        for i, title in enumerate(header):\n",
    "            align_val = Align.C\n",
    "            new_x_pos = XPos.RIGHT if i < len(header) - 1 else XPos.LMARGIN\n",
    "            new_y_pos = YPos.TOP if i < len(header) - 1 else YPos.NEXT\n",
    "            header_text = encode_string_for_pdf(title)\n",
    "            self.cell(col_widths[i], 7, header_text, border=1, align=align_val, new_x=new_x_pos, new_y=new_y_pos)\n",
    "\n",
    "        self.set_font('Helvetica', '', 8)\n",
    "        for row in data: \n",
    "            y_start = self.get_y()\n",
    "\n",
    "            title_chars_per_line_est = col_widths[6] * 2 if col_widths[6] > 0 else 1\n",
    "            title_lines = math.ceil(len(str(row[6])) / title_chars_per_line_est) if title_chars_per_line_est > 0 else 1\n",
    "            needed_height = max(5, title_lines * 4)\n",
    "\n",
    "            if y_start + needed_height > self.h - self.b_margin:\n",
    "                self.add_page()\n",
    "                self.set_font('Helvetica', 'B', 8)\n",
    "                for i, title_h in enumerate(header):\n",
    "                    align_val = Align.C\n",
    "                    new_x_pos = XPos.RIGHT if i < len(header) - 1 else XPos.LMARGIN\n",
    "                    new_y_pos = YPos.TOP if i < len(header) - 1 else YPos.NEXT\n",
    "                    header_text_new = encode_string_for_pdf(title_h)\n",
    "                    self.cell(col_widths[i], 7, header_text_new, border=1, align=align_val, new_x=new_x_pos, new_y=new_y_pos)\n",
    "                self.set_font('Helvetica', '', 8)\n",
    "                y_start = self.get_y()\n",
    "\n",
    "            current_max_y = y_start\n",
    "            align_map = [Align.R, Align.R, Align.R, Align.R, Align.R, Align.C, Align.L]\n",
    "            current_x = self.l_margin\n",
    "            for idx, (cell_data, width, align_val) in enumerate(zip(row, col_widths, align_map)):\n",
    "                self.set_xy(current_x, y_start)\n",
    "                processed_data = encode_string_for_pdf(cell_data)\n",
    "                self.multi_cell(width, 5, processed_data, border=0, align=align_val)\n",
    "                current_max_y = max(current_max_y, self.get_y())\n",
    "                current_x += width\n",
    "\n",
    "            self.set_y(y_start)\n",
    "            x = self.l_margin\n",
    "            self.line(x, y_start, x, current_max_y)\n",
    "            for w in col_widths:\n",
    "                x += w\n",
    "                self.line(x, y_start, x, current_max_y)\n",
    "            self.line(self.l_margin, current_max_y, self.w - self.r_margin, current_max_y)\n",
    "            self.set_y(current_max_y)\n",
    "\n",
    "\n",
    "def save_results_to_pdf(filename, author_details, l_index, processed_count, total_pubs_reported, top_pubs, was_rate_limited, skips_info):\n",
    "    \"\"\"Saves the calculation results to a PDF file with the updated format.\"\"\"\n",
    "    try:\n",
    "        pdf = PDF(orientation='L', unit='mm', format='A4')\n",
    "        pdf.add_page()\n",
    "\n",
    "        author_name = author_details.get('name', 'N/A')\n",
    "        pdf.set_font('Helvetica', 'B', 14)\n",
    "        pdf.multi_cell(0, 10, author_name, border=0, align='L', new_x=XPos.LMARGIN, new_y=YPos.NEXT)\n",
    "\n",
    "        pdf.set_font('Helvetica', '', 10)\n",
    "        affiliation = author_details.get('affiliation')\n",
    "        if affiliation:\n",
    "            pdf.multi_cell(0, 5, affiliation, align='L', new_x=XPos.LMARGIN, new_y=YPos.NEXT)\n",
    "        else: pdf.ln(1)\n",
    "\n",
    "        interests = author_details.get('interests')\n",
    "        if interests:\n",
    "            interests_str = \", \".join(interests)\n",
    "            pdf.multi_cell(0, 5, interests_str, align='L', new_x=XPos.LMARGIN, new_y=YPos.NEXT)\n",
    "        else: pdf.ln(1)\n",
    "\n",
    "        profile_url = None\n",
    "        scholar_id = author_details.get('scholar_id')\n",
    "        if scholar_id:\n",
    "            profile_url = f\"https://scholar.google.com/citations?user={scholar_id}\"\n",
    "            pdf.set_text_color(0, 0, 255); pdf.set_font('', 'U')\n",
    "            pdf.cell(0, 5, profile_url, link=profile_url, align='L', new_x=XPos.LMARGIN, new_y=YPos.NEXT)\n",
    "            pdf.set_font('', ''); pdf.set_text_color(0, 0, 0)\n",
    "        else: pdf.ln(1)\n",
    "\n",
    "        pdf.ln(5)\n",
    "\n",
    "        if was_rate_limited:\n",
    "            pdf.set_text_color(255, 0, 0); pdf.set_font('Helvetica', 'B', 10)\n",
    "            pdf.multi_cell(0, 5, \"*** WARNING: Processing aborted early due to Google Scholar rate limit (429 errors). Results are based on incomplete data. ***\", border=0, align='L', new_x=XPos.LMARGIN, new_y=YPos.NEXT)\n",
    "            pdf.set_text_color(0, 0, 0); pdf.ln(2)\n",
    "\n",
    "        pdf.key_value(\"L-index\", f\"{l_index:.2f}\" if l_index is not None else \"Error\")\n",
    "\n",
    "        pdf.set_font('Helvetica', 'I', 9)\n",
    "        current_date_str = datetime.datetime.now().strftime(\"%d %B %Y\")\n",
    "        calc_basis_str = f\"Calculated on {current_date_str} based on the {total_pubs_reported} most cited publications\"\n",
    "        pdf.multi_cell(0, 5, calc_basis_str, align='L', new_x=XPos.LMARGIN, new_y=YPos.NEXT)\n",
    "        pdf.set_font('Helvetica', '', 10)\n",
    "        pdf.ln(1)\n",
    "\n",
    "        pdf.ln(5)\n",
    "\n",
    "        pubs_to_show_in_table = top_pubs[:TOP_N_PUBS_TO_SAVE_IN_REPORT]\n",
    "        pdf.chapter_title(f\"Top {len(pubs_to_show_in_table)} Contributing Publications\")\n",
    "\n",
    "        if not pubs_to_show_in_table:\n",
    "            pdf.cell(0, 6, \"(No publications processed had a contribution score > 0 or process was stopped early)\", border=0, align='L', new_x=XPos.LMARGIN, new_y=YPos.NEXT)\n",
    "        else:\n",
    "            header = ['#', 'Score', 'Cites', 'Authors', 'Age', 'Year', 'Title']\n",
    "            table_data = []\n",
    "            for i, pub_data in enumerate(pubs_to_show_in_table):\n",
    "                rank_str = f\"{i+1}.\"\n",
    "                term_str = f\"{pub_data['term']:.1f}\"\n",
    "                c_str = str(pub_data['citations'])\n",
    "                a_str = str(pub_data['authors'])\n",
    "                y_str = str(pub_data['age'])\n",
    "                yr_str = str(pub_data['year'])\n",
    "                title_str = str(pub_data['title'])[:150] + ('...' if len(str(pub_data['title'])) > 150 else '')\n",
    "                table_data.append([rank_str, term_str, c_str, a_str, y_str, yr_str, title_str])\n",
    "            pdf.publication_table(header, table_data)\n",
    "\n",
    "        pdf.ln(10)\n",
    "        pdf.set_font('Helvetica','', 8)\n",
    "        current_year = datetime.datetime.now().year\n",
    "        footer1 = f\"L-index Calculator by Aleksey V. Belikov, 2025\"\n",
    "        footer2 = f\"L-index concept by Aleksey V. Belikov & Vitaly V. Belikov, 2015\"\n",
    "        pdf.cell(0, 5, footer1, align='L', new_x=XPos.LMARGIN, new_y=YPos.NEXT)\n",
    "        pdf.cell(0, 5, footer2, align='L', new_x=XPos.LMARGIN, new_y=YPos.NEXT)\n",
    "\n",
    "        pdf.set_font('Helvetica', 'B', 8)\n",
    "        pdf.cell(0, 5, \" \", align='L', new_x=XPos.LMARGIN, new_y=YPos.NEXT)\n",
    "        pdf.set_font('Helvetica','', 8)\n",
    "        citation_text = \"Belikov AV and Belikov VV. A citation-based, author- and age-normalized, logarithmic index for evaluation of individual researchers independently of publication counts. F1000Research 2015, 4:884\"\n",
    "        citation_url = \"https://doi.org/10.12688/f1000research.7070.1\"\n",
    "        pdf.multi_cell(0, 4, citation_text, align='L', new_x=XPos.LMARGIN, new_y=YPos.NEXT)\n",
    "        pdf.set_text_color(0, 0, 255); pdf.set_font('', 'U')\n",
    "        pdf.cell(0, 4, f\"({citation_url})\", align='L', link=citation_url, new_x=XPos.LMARGIN, new_y=YPos.NEXT)\n",
    "        pdf.set_text_color(0, 0, 0); pdf.set_font('', '')\n",
    "\n",
    "        pdf.output(filename)\n",
    "        logger.info(f\"Results successfully saved to PDF: {filename}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to generate PDF report: {e}\", exc_info=True)\n",
    "        print(f\"\\nError: Could not generate PDF report '{filename}'. Check logs.\")\n",
    "\n",
    "\n",
    "def calculate_l_index(author_name_or_id, max_pubs_limit):\n",
    "    \"\"\"Searches for an author, calculates their L-Index, and fetches details.\"\"\"\n",
    "    preliminary_index_I = 0.0\n",
    "    processed_pubs_count = 0\n",
    "    author_details = {'name': 'N/A', 'affiliation': None, 'interests': [], 'scholar_id': None, 'citedby': 'N/A'}\n",
    "    publication_details = []\n",
    "    rate_limited = False\n",
    "    total_pubs_reported = 0\n",
    "    i = -1 \n",
    "\n",
    "    try:\n",
    "        logger.info(f\"Searching for author: {author_name_or_id}\")\n",
    "        is_id_search = bool(re.match(r'^[\\w-]{12}$', author_name_or_id))\n",
    "        author_to_process = None\n",
    "\n",
    "        if is_id_search:\n",
    "            try:\n",
    "                author_stub = scholarly.scholarly.search_author_id(author_name_or_id, filled=False)\n",
    "                if not author_stub:\n",
    "                    raise ValueError(f\"No author found for ID '{author_name_or_id}'.\")\n",
    "                author_details['scholar_id'] = author_stub.get('scholar_id')\n",
    "                author_details['name'] = author_stub.get('name', 'Name Not Found')\n",
    "                author_to_process = author_stub\n",
    "                if not author_details['scholar_id']: raise ValueError(\"Author ID search returned result without scholar_id.\")\n",
    "                logger.info(f\"Found author by ID: {author_details['name']} (ID: {author_details['scholar_id']})\")\n",
    "            except MaxTriesExceededException as rt_err: logger.error(f\"Rate limit during author ID lookup: {rt_err}. Aborting.\"); rate_limited = True; return None, author_details, 0.0, 0, 0, [], rate_limited, i\n",
    "            except StopIteration:\n",
    "                 logger.error(f\"No author found for ID '{author_name_or_id}'. ID might be invalid or profile private/removed.\")\n",
    "                 return None, author_details, 0.0, 0, 0, [], rate_limited, i\n",
    "            except Exception as e: logger.error(f\"Failed during author ID lookup: {e}\", exc_info=False); return None, author_details, 0.0, 0, 0, [], rate_limited, i\n",
    "        else: \n",
    "             potential_authors = []\n",
    "             try:\n",
    "                  search_query = scholarly.scholarly.search_author(author_name_or_id)\n",
    "                  for idx in range(MAX_SEARCH_RESULTS_TO_CHECK):\n",
    "                     try:\n",
    "                         auth = next(search_query, None)\n",
    "                         if auth is None: break\n",
    "                         if auth and 'scholar_id' in auth: potential_authors.append(auth)\n",
    "                         elif auth: logger.warning(f\"Search result missing 'scholar_id': {auth.get('name', 'N/A')}\")\n",
    "                     except StopIteration: break\n",
    "                     except MaxTriesExceededException as rt_err_inner: logger.error(f\"Rate limit during author search iteration {idx+1}: {rt_err_inner}. Stopping search.\"); rate_limited = True; break\n",
    "                     except Exception as e_inner: logger.error(f\"Error during author search iteration {idx+1}: {e_inner}. Stopping search.\"); break \n",
    "                  logger.info(f\"Found {len(potential_authors)} potential author(s) with IDs.\")\n",
    "             except MaxTriesExceededException as rt_err: logger.error(f\"Rate limit during initial author search setup: {rt_err}. Aborting.\"); rate_limited = True\n",
    "             except StopIteration: logger.info(f\"Found {len(potential_authors)} potential author(s) with IDs (StopIteration caught).\")\n",
    "             except Exception as e: logger.error(f\"Error during author search setup: {e}\", exc_info=False); potential_authors = []\n",
    "\n",
    "             if rate_limited: return None, author_details, 0.0, 0, 0, [], rate_limited, i\n",
    "             if not potential_authors: logger.error(f\"Author '{author_name_or_id}' not found or no suitable matches retrieved.\"); return None, author_details, 0.0, 0, 0, [], rate_limited, i\n",
    "\n",
    "             best_match_author = None; highest_ratio = 0.0; query_lower = author_name_or_id.lower()\n",
    "             logger.info(\"Evaluating potential matches:\")\n",
    "             for pa in potential_authors:\n",
    "                 name_lower = pa.get('name', '').lower();\n",
    "                 if not name_lower: continue\n",
    "                 ratio = SequenceMatcher(None, query_lower, name_lower).ratio()\n",
    "                 logger.info(f\"  - Candidate: '{pa.get('name', 'N/A')}', ID: {pa.get('scholar_id', 'N/A')}, Aff: {pa.get('affiliation', 'N/A')}, Ratio: {ratio:.3f}\")\n",
    "                 if ratio > highest_ratio:\n",
    "                     highest_ratio = ratio\n",
    "                     best_match_author = pa\n",
    "                 elif ratio == highest_ratio and best_match_author:\n",
    "                     logger.info(f\"  - Note: Equal ratio {ratio:.3f} found for '{pa.get('name', 'N/A')}' and '{best_match_author.get('name', 'N/A')}'. Keeping first best match.\")\n",
    "                     pass\n",
    "\n",
    "             selected_author_final = None\n",
    "             effective_threshold = NAME_SIMILARITY_THRESHOLD\n",
    "             if len(potential_authors) == 1:\n",
    "                 effective_threshold = SINGLE_RESULT_SIMILARITY_THRESHOLD\n",
    "                 logger.info(f\"Only one result found. Using adjusted threshold for selection: {effective_threshold:.2f}\")\n",
    "\n",
    "             if best_match_author and highest_ratio >= effective_threshold:\n",
    "                 selected_author_final = best_match_author\n",
    "                 logger.info(f\"Selected author based on highest ratio >= threshold: {selected_author_final['name']} (Ratio: {highest_ratio:.3f})\")\n",
    "             else:\n",
    "                 logger.warning(f\"Could not find a confident match. Best match '{best_match_author.get('name', 'N/A') if best_match_author else 'None'}' had ratio {highest_ratio:.3f} (Threshold: {effective_threshold:.2f}).\")\n",
    "                 logger.error(f\"Failed to identify a sufficiently similar author match.\")\n",
    "                 return None, author_details, 0.0, 0, 0, [], rate_limited, i\n",
    "\n",
    "             author_to_process = selected_author_final \n",
    "             author_details['scholar_id'] = author_to_process.get('scholar_id')\n",
    "             author_details['name'] = author_to_process.get('name', 'Name Not Found') \n",
    "\n",
    "        if not author_to_process or not author_details.get('scholar_id'):\n",
    "            logger.error(\"Author selection process failed to yield a valid author object or ID.\")\n",
    "            return None, author_details, 0.0, 0, 0, [], rate_limited, i\n",
    "\n",
    "        logger.info(f\"Fetching full profile details for {author_details.get('name', 'N/A')} (ID: {author_details.get('scholar_id')})...\")\n",
    "        author_filled_profile = None\n",
    "        try:\n",
    "            sections_to_fill = ['basics', 'indices', 'interests', 'coauthors', 'counts']\n",
    "            author_filled_profile = scholarly.scholarly.fill(author_to_process, sections=sections_to_fill)\n",
    "\n",
    "            author_details['name'] = author_filled_profile.get('name', author_details.get('name'))\n",
    "            author_details['affiliation'] = author_filled_profile.get('affiliation', author_details.get('affiliation'))\n",
    "            author_details['interests'] = author_filled_profile.get('interests', author_details.get('interests', []))\n",
    "            author_details['citedby'] = author_filled_profile.get('citedby', author_details.get('citedby', 'N/A'))\n",
    "\n",
    "            logger.info(f\"Successfully fetched profile details. Name: '{author_details['name']}', Affiliation: '{author_details.get('affiliation', 'N/A')}', Total citations reported: {author_details['citedby']}\")\n",
    "\n",
    "        except MaxTriesExceededException as rt_err:\n",
    "            logger.error(f\"Rate limit occurred while fetching full profile details: {rt_err}. Proceeding with potentially incomplete author info (using stub data if available).\")\n",
    "            rate_limited = True\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error filling author profile: {e}. Proceeding with potentially incomplete author info.\", exc_info=False)\n",
    "\n",
    "        logger.info(f\"Fetching initial publication list (sorted by citedby, limit {max_pubs_limit})...\")\n",
    "        initial_pubs = []\n",
    "        try:\n",
    "            author_obj_for_pubs = author_filled_profile if author_filled_profile else author_to_process\n",
    "            if 'publications' not in author_obj_for_pubs:\n",
    "                logger.info(\"Filling publications section...\")\n",
    "                author_pubs_filled = scholarly.scholarly.fill(\n",
    "                    author_obj_for_pubs,\n",
    "                    sections=['publications'],\n",
    "                    sortby='citedby',\n",
    "                    publication_limit=max_pubs_limit\n",
    "                )\n",
    "            else: \n",
    "                 logger.info(\"Publications section already present, using existing data (up to limit).\")\n",
    "                 author_pubs_filled = author_obj_for_pubs\n",
    "\n",
    "            if not author_pubs_filled or 'publications' not in author_pubs_filled or author_pubs_filled['publications'] is None:\n",
    "                initial_pubs = []\n",
    "            else:\n",
    "                initial_pubs = author_pubs_filled.get('publications', [])[:max_pubs_limit]\n",
    "\n",
    "        except MaxTriesExceededException as rt_err:\n",
    "            logger.error(f\"Rate limit occurred while fetching publication list: {rt_err}. Aborting calculation.\")\n",
    "            rate_limited = True\n",
    "            return None, author_details, 0.0, 0, 0, [], rate_limited, i\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error fetching publication list: {e}\", exc_info=False)\n",
    "            return None, author_details, 0.0, 0, 0, [], rate_limited, i\n",
    "\n",
    "        total_pubs_reported = len(initial_pubs)\n",
    "        if not initial_pubs and not rate_limited:\n",
    "            logger.warning(f\"No publications found for author {author_details.get('name')}. L-index will be 0.\")\n",
    "            return 0.0, author_details, 0.0, 0, total_pubs_reported, [], rate_limited, i\n",
    "\n",
    "        pubs_to_process = initial_pubs\n",
    "        num_selected = len(pubs_to_process)\n",
    "        logger.info(f\"Fetched {num_selected} publications (limit was {max_pubs_limit}). Starting processing...\")\n",
    "        current_year = datetime.datetime.now().year\n",
    "        skipped_count_within_top_n = 0\n",
    "\n",
    "        for i, pub_stub in enumerate(pubs_to_process):\n",
    "            if rate_limited:\n",
    "                 logger.warning(f\"Stopping publication processing at pub {i+1} due to earlier rate limit.\")\n",
    "                 break\n",
    "\n",
    "            pub_title_guess = pub_stub.get('bib', {}).get('title', 'Unknown Title')\n",
    "            logger.info(f\"Processing pub {i+1}/{num_selected}: '{pub_title_guess[:60]}...'\")\n",
    "\n",
    "            try:\n",
    "                pub = None\n",
    "                author_str = ''\n",
    "                num_authors = 1 \n",
    "\n",
    "                try:\n",
    "                    pub = scholarly.scholarly.fill(pub_stub)\n",
    "                    bib = pub.get('bib', {})\n",
    "                    author_str = bib.get('author', '')\n",
    "                    num_authors_temp = count_authors(author_str)\n",
    "                    if num_authors_temp is None:\n",
    "                        logger.warning(f\"Could not reliably count authors for pub {i+1} ('{pub_title_guess[:50]}...'). Assuming 1 author.\")\n",
    "                        num_authors = 1\n",
    "                    else:\n",
    "                        num_authors = num_authors_temp\n",
    "                except MaxTriesExceededException as rt_err:\n",
    "                    logger.error(f\"Rate limit hit while filling details for pub {i+1} ('{pub_title_guess[:50]}...'): {rt_err}. Aborting further processing.\")\n",
    "                    rate_limited = True\n",
    "                    skipped_count_within_top_n += 1\n",
    "                    break\n",
    "                except Exception as fill_err:\n",
    "                    logger.error(f\"Failed to fill details for pub {i+1} ('{pub_title_guess[:50]}...'): {fill_err}. Will use stub data and assume 1 author.\", exc_info=False)\n",
    "                    pub = pub_stub\n",
    "                    bib = pub_stub.get('bib', {})\n",
    "                    author_str = bib.get('author', '') \n",
    "                    num_authors = 1 \n",
    "                    logger.warning(f\"Assuming 1 author for pub {i+1} due to fill error.\")\n",
    "                \n",
    "                citations = pub.get('num_citations', pub_stub.get('num_citations', 0))\n",
    "                pub_year_str = bib.get('pub_year', None)\n",
    "                title = bib.get('title', 'Title Not Available')\n",
    "\n",
    "                if pub_year_str is None:\n",
    "                    logger.warning(f\"Skipping pub {i+1} ('{title[:50]}...') due to missing publication year.\")\n",
    "                    skipped_count_within_top_n += 1\n",
    "                    continue\n",
    "                try:\n",
    "                    pub_year = int(pub_year_str)\n",
    "                    if pub_year > current_year + 2 or pub_year < 1800: \n",
    "                        logger.warning(f\"Skipping pub {i+1} ('{title[:50]}...') due to potentially invalid year: {pub_year}.\")\n",
    "                        skipped_count_within_top_n += 1\n",
    "                        continue\n",
    "                except ValueError:\n",
    "                    logger.warning(f\"Skipping pub {i+1} ('{title[:50]}...') due to non-integer year format: '{pub_year_str}'.\")\n",
    "                    skipped_count_within_top_n += 1\n",
    "                    continue\n",
    "\n",
    "                \n",
    "                citations = citations if citations is not None else 0\n",
    "\n",
    "                age = max(1, current_year - pub_year + 1)\n",
    "\n",
    "                denominator = num_authors * age\n",
    "\n",
    "                term = citations / denominator\n",
    "\n",
    "                pub_data = {\n",
    "                    'term': term,\n",
    "                    'title': title,\n",
    "                    'year': pub_year,\n",
    "                    'citations': citations,\n",
    "                    'authors': num_authors,\n",
    "                    'age': age\n",
    "                }\n",
    "                publication_details.append(pub_data)\n",
    "                preliminary_index_I += term\n",
    "                processed_pubs_count += 1\n",
    "\n",
    "                if (processed_pubs_count % 25 == 0) and processed_pubs_count > 0: # Log more frequently if needed\n",
    "                    logger.info(f\"Processed {processed_pubs_count}/{num_selected} pubs...\")\n",
    "\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Critical error processing pub {i+1} ('{pub_title_guess[:50]}...'): {e}\", exc_info=False)\n",
    "                skipped_count_within_top_n += 1\n",
    "\n",
    "        if skipped_count_within_top_n > 0:\n",
    "            logger.warning(f\"Skipped {skipped_count_within_top_n} publications within the attempted set ({i+1} pubs) due to missing/invalid data or processing errors.\")\n",
    "\n",
    "\n",
    "        l_index = math.log(preliminary_index_I + 1)\n",
    "\n",
    "        logger.info(\"Sorting processed publications by contribution score (term)...\")\n",
    "        sorted_contributors = sorted(publication_details, key=lambda p: p['term'], reverse=True)\n",
    "\n",
    "        positive_term_contributors = [p for p in sorted_contributors if p['term'] > 0]\n",
    "        logger.info(f\"Identified {len(positive_term_contributors)} processed publications with a contribution score > 0.\")\n",
    "\n",
    "        top_contributing_list = sorted_contributors\n",
    "\n",
    "        if rate_limited:\n",
    "            logger.warning(\"Calculation finished BUT was affected or aborted early due to Google Scholar rate limiting.\")\n",
    "        else:\n",
    "            logger.info(\"Calculation process completed.\")\n",
    "            if i + 1 < num_selected:\n",
    "                logger.warning(f\"Processing loop did not complete all {num_selected} fetched publications (stopped at {i+1}). This might indicate an error not caught as rate limit.\")\n",
    "\n",
    "        return l_index, author_details, preliminary_index_I, processed_pubs_count, total_pubs_reported, top_contributing_list, rate_limited, i\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An unexpected critical error occurred during the main calculation process: {e}\", exc_info=True)\n",
    "        if 'i' not in locals(): i = -1\n",
    "        return None, author_details, preliminary_index_I, processed_pubs_count, total_pubs_reported, [], rate_limited, i\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"-\" * 60)\n",
    "    print(\"L-index Calculator by Aleksey V. Belikov\")\n",
    "    print(\"-\" * 60)\n",
    "    max_pubs_limit = MAX_PUBS_TO_PROCESS\n",
    "    print(\"-\" * 60)\n",
    "    print(\"IMPORTANT NOTES:\")\n",
    "    print(\"1. Results are entirely dependent on the accuracy, completeness and public availability of the scientist's Google Scholar profile\")\n",
    "    print(\"2. While the script attempts to find the best match for an author's name, errors can occur, especially for common names\")\n",
    "    print(\"3. Check the affiliation, keywords and top publications in the output pdf to verify that the correct scientist has been identified\")\n",
    "    print(\"4. Using the Google Scholar ID is recommended, it can be found at the end of the profile URL\")\n",
    "    print(\"5. The count_authors function estimates author numbers, which can sometimes be imprecise for complex author strings or large consortia\")\n",
    "    print(f\"6. Calculation is based on the {max_pubs_limit} most cited publications found (or fewer if author has less)\")\n",
    "    print(\"7. This can be changed by modifying MAX_PUBS_TO_PROCESS parameter in the code\")\n",
    "    print(\"8. Extensive requests can lead to temporary IP blocks (rate limiting) from Google Scholar, so it is recommended to keep MAX_PUBS_TO_PROCESS to 100\")\n",
    "    print(\"9. It is recommended to wait (hours, or even a day) if you encounter persistent rate limiting, or try a different IP address or a proxy\")\n",
    "    print(\"10. Selecting too low a MAX_PUBS_TO_PROCESS value will lead to underestimation of the L-index\")\n",
    "    print(\"11. Nevertheless, 100 most cited publications capture the bulk of the L-index, even for authors with many hundreds of publications\")\n",
    "    print(\"12. Always compare scientists using the same MAX_PUBS_TO_PROCESS value to calculate their L-indices\")\n",
    "    print(f\"13. A PDF report including the top {TOP_N_PUBS_TO_SAVE_IN_REPORT} contributing publications will be saved in the '{OUTPUT_DIR}' directory\")\n",
    "    print(\"14. The number of the top contributing publications in the pdf report can be changed by modifying TOP_N_PUBS_TO_SAVE_IN_REPORT parameter in the code\")\n",
    "    print(\"15. The PDF generation uses latin-1 encoding with replacements for unsupported characters. Some special characters in names or titles might not render perfectly\")\n",
    "    print(\"-\" * 60)\n",
    "    print(\"Enter Author Name or Google Scholar ID in a pop-up window\")\n",
    "\n",
    "    author_query = input(\"Enter Author Name or Google Scholar ID: \")\n",
    "\n",
    "    if not author_query:\n",
    "        print(\"No author name or ID provided. Exiting.\")\n",
    "    else:\n",
    "        l_index, author_data, prelim_I, processed_count, total_reported, top_contrib_pubs, was_rate_limited, last_attempted_index = calculate_l_index(\n",
    "            author_query,\n",
    "            max_pubs_limit\n",
    "        )\n",
    "\n",
    "        author_full_name = author_data.get('name')\n",
    "        if author_full_name is None or author_full_name == 'N/A':\n",
    "             author_full_name_display = \"N/A (Could not be determined)\"\n",
    "        else:\n",
    "             author_full_name_display = author_full_name\n",
    "\n",
    "        if was_rate_limited:\n",
    "            print(\"\\n--- WARNING: RATE LIMITED ---\")\n",
    "            print(f\"Processing may have stopped early due to Google Scholar rate limits.\")\n",
    "            print(\"Results shown below might be based on INCOMPLETE data gathered before the limit was hit.\")\n",
    "            print(f\"If errors persist, please wait a significant amount of time (e.g., hours) before trying again.\")\n",
    "            if author_full_name_display.startswith(\"N/A\"):\n",
    "                 print(\"Rate limit may have occurred before the author could be definitively identified.\")\n",
    "            print(\"-\" * 60)\n",
    "\n",
    "        if author_data.get('scholar_id'):\n",
    "            if l_index is None:\n",
    "                 print(f\"\\n--- Calculation Error ---\")\n",
    "                 print(f\"Author Identified: {author_full_name_display} (ID: {author_data.get('scholar_id', 'N/A')})\")\n",
    "                 print(f\"Affiliation:       {author_data.get('affiliation', 'N/A')}\")\n",
    "                 print(f\"Could not complete L-index calculation due to errors after author identification.\")\n",
    "                 print(f\"(Attempted to process up to publication {last_attempted_index + 1 if last_attempted_index != -1 else 'N/A'} out of {total_reported} fetched).\")\n",
    "                 print(f\"(Successfully processed {processed_count} publications before error/stop).\")\n",
    "                 print(\"Please check the script's log output for detailed error messages.\")\n",
    "\n",
    "            else:\n",
    "                print(\"\\n--- Results Summary ---\")\n",
    "                if was_rate_limited: print(\"(NOTE: Results based on potentially INCOMPLETE data due to rate limiting)\")\n",
    "                print(f\"Author Identified: {author_full_name_display}\")\n",
    "                print(f\"Affiliation:       {author_data.get('affiliation', 'N/A')}\")\n",
    "                print(f\"Interests:         {', '.join(author_data.get('interests', [])) if author_data.get('interests') else 'N/A'}\")\n",
    "                scholar_id = author_data.get('scholar_id')\n",
    "                print(f\"Scholar Profile:   {'https://scholar.google.com/citations?user=' + scholar_id if scholar_id else 'N/A'}\")\n",
    "                print(f\"L-Index:           {l_index:.2f}\")\n",
    "                print(f\"Calculation Basis: The {total_reported} most cited publications fetched from Google Scholar.\")\n",
    "                print(f\"Pubs Processed:    {processed_count} / {total_reported} (Fetched)\")\n",
    "\n",
    "                pubs_attempted_in_loop = last_attempted_index + 1 if last_attempted_index != -1 else 0\n",
    "                skips_within_attempted_group = max(0, pubs_attempted_in_loop - processed_count)\n",
    "                unreached_due_to_stop = max(0, total_reported - pubs_attempted_in_loop)\n",
    "                total_unprocessed_within_fetched = skips_within_attempted_group + unreached_due_to_stop\n",
    "\n",
    "                if total_unprocessed_within_fetched > 0:\n",
    "                     print(f\"Note: {total_unprocessed_within_fetched} publications within the fetched {total_reported} were not fully processed.\")\n",
    "                     if skips_within_attempted_group > 0:\n",
    "                         print(f\"      - {skips_within_attempted_group} were attempted (up to pub #{pubs_attempted_in_loop}) but failed detail fetch, validation, or had invalid data (check logs).\")\n",
    "                     if unreached_due_to_stop > 0:\n",
    "                         reason = \"rate limit or other processing stop\" if was_rate_limited else \"an early processing stop (check logs)\"\n",
    "                         print(f\"      - {unreached_due_to_stop} were not reached in the processing loop (after pub #{pubs_attempted_in_loop}) likely due to {reason}.\")\n",
    "\n",
    "                skips_info_pdf = {\n",
    "                    'total': total_unprocessed_within_fetched,\n",
    "                    'failed_processing': skips_within_attempted_group,\n",
    "                    'unreached_limit': unreached_due_to_stop\n",
    "                 }\n",
    "\n",
    "                if author_full_name and author_full_name != 'N/A':\n",
    "                    try:\n",
    "                        safe_filename_base = sanitize_filename(f\"{author_full_name}_{author_data.get('scholar_id', 'NoID')}\")\n",
    "                        status_tag = \"_RATE_LIMITED\" if was_rate_limited else \"\"\n",
    "                        date_str = datetime.date.today().isoformat()\n",
    "                        pdf_filename = os.path.join(OUTPUT_DIR, f\"{safe_filename_base}_L-Index_BasedOn{max_pubs_limit}{status_tag}_{date_str}.pdf\")\n",
    "                        os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "                        save_results_to_pdf(\n",
    "                            pdf_filename,\n",
    "                            author_data,\n",
    "                            l_index,\n",
    "                            processed_count,\n",
    "                            total_reported,\n",
    "                            top_contrib_pubs,\n",
    "                            was_rate_limited,\n",
    "                            skips_info_pdf\n",
    "                        )\n",
    "                    except Exception as pdf_err:\n",
    "                        pass \n",
    "                else:\n",
    "                    logger.warning(\"Skipping PDF generation because a valid author name could not be determined for the filename.\")\n",
    "                    print(\"\\nWarning: PDF report generation skipped as author name was not fully determined.\")\n",
    "\n",
    "        elif not was_rate_limited:\n",
    "             print(\"\\n--- Author Not Found ---\")\n",
    "             print(\"Could not calculate L-index.\")\n",
    "             print(\"Reason: Author not found or no confident match identified via search.\")\n",
    "             print(\"Please check the spelling or try the Google Scholar ID if known.\")\n",
    "\n",
    "        print(\"-\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
